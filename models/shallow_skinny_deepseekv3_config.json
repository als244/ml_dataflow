{
    "embed_dtype": "bf16",
    "attn_dtype": "bf16",
    "router_dtype": "bf16",
    "expert_dtype": "bf16",
    "head_dtype": "bf16",
    "vocab_size": 129280,
    "model_dim": 7168,
    "n_layers": 6,
    "n_heads": 56,
    "n_kv_heads": 8,
    "qk_norm_type": "none",
    "qk_norm_weight_type": "none",
    "num_shared_experts": 0,
    "num_routed_experts": 64,
    "top_k_routed_experts": 2,
    "expert_dim": 2048,
    "expert_mlp_type": "swiglu",
    "rope_theta": 1000000,
    "rms_norm_epsilon": 1e-5,
    "rand_seed": 42
}
